---
title: Redis の無停止マイグレーションと ElastiCache そして Redis Sentinel
date: 2017-11-05
tags: infra
---

やんごとなき事情により、CentOS 6 が動く古いサーバをつぶしていくというようなことを普段やっていて、Cent OS 6 上で動く Redis をどのように移行しようか、ということを最近考える機会があったので、このエントリにメモしておきます。

オンプレミスではなく AWS の EC2 や ElastiCache に寄せていくということと、Redis を利用するアプリケーションサーバでは Ruby on Rails が動いているという暗黙の前提があるため、そのつもりで読んでいただければと思います。

## 無停止で Redis サーバをマイグレーションすることの困難さ

Ubuntu 16.04 用に Redis サーバを準備するのはそれほど大変な作業ではありません。キャパシティプランニングさえ終えれば、あとはちょっと Itamae や Chef のレシピを書いてやるだけ、です。

問題は切り替え方法です。アプリケーションをメンテ状態にできるなら一番簡単です。しかし、たとえば会社の根幹をなすような重要なサービスであったりすると、様々な部署との調整も発生しますし、おいそれと止めるわけにはいかないでしょう。

ただし、明示的にメンテナンス状態にせずとも、切り替え中のエラーはある程度許容する、というポリシーで切り替えることは可能です。たとえば、10 秒ほどならば 5xx が返る期間があっても、それは必要な対価として受け入れられるでしょう。それが数十分となると、許容することはできないかもしれませんが..。

このように、いかにダウンタイムをゼロに近づけつつシュッと切り替えられるかが SRE の経験が生きてくるところでしょう。というわけで、動き続けている Redis を新しいサーバに移すために、どのような方法があるのかを考えていきます。

## レプリケーションによる(ほぼ)無停止マイグレーション

プラットフォームとして AWS を利用している場合、一般的に要件を満たすならばなるべくマネージドサービスに寄せていくほうがメンテナンスコストが下がってよいでしょう。そこで、最初に候補に上がるのが ElastiCache Redis です。条件付きですが (後述)、multi-az 間での自動フェイルオーバーが可能で、ElastiCache を使うことができれば運用不可がぐっと下がるため、できれば使っていきたいところです。

あれこれ考えた結果、ElastiCache への無停止マイグレーションは困難、という結論に落ち着きました。

今回のようなケースだと、master にはすでに VIP がついているため、以下の図のような手順でほぼ無停止マイグレーションが可能です。

<a href="/2017/11/05/redis_sentinel_tutorial/redis_structure.png">
  <img src="/2017/11/05/redis_sentinel_tutorial/redis_structure.png" alt="レプリケーションによる Redis の切り替え例" style="width: 700px;">
</a>

app はアプリケーションサーバ群、201~204 は現在動いている旧 Redis インスタンス、301 および 302 は移行先の新しい Redis のインスタンスであるとします。

今回は計 4 台のレプリケーショングループとして動く旧 Redis インスタンスを、リソースの状況を見たところ 1 台でまかなえそうなため、1 台の Redis を active/standby 構成にし、そちらに切り替えるという例を見ていきます。

1. 初期状態
  - app が VIP を通じて master に write、slave への read は ELB で分散。201 -> 202,203,204 に対して非同期レプリケーションしている
2. 新しい Redis サーバを用意する
  - リソースの利用状況を考えると read/write ともに一台のサーバでまかなえそうなので、301 をアクティブ、302 をスタンバイ構成にする
  - 201 から 301 にレプリケーションされるようにし、301 から 302 へレプリケーションされるようにする
  - HA 構成にするために Pacemaker あるいは Redis Sentinel (後述) や Redis Cluster を使う
3. アプリケーションの Redis の設定を更新し、slave として 301 を指定してデプロイ
  - 問題ないかしばらく観察する
4. アプリケーションの Redis の設定を更新し、master として 301 を指定してデプロイ
  - 以降先が EC2 なら単純に VIP を切り替えるだけでもよい

この切替方法は、ElastiCache を移行先に選んだ場合には不可能になります。なぜなら、ElastiCache Redis のインスタンスでは `SLACEOF` コマンドが利用できず、201 の slave としてぶら下げることができないからです。(参考: [制限されるコマンド - Amazon ElastiCache](http://docs.aws.amazon.com/ja_jp/AmazonElastiCache/latest/UserGuide/ClientConfig.RestrictedCommands.html))


### 余談: ElastiCache の t2 インスタンスの自動フェイルオーバ

ElastiCache Redis には非クラスターモードとクラスターモードという 2 種類の扱い方があり、非クラスターモードはクラスタという概念がない素の Redis に無理やり(?)クラスタっぽい扱い方をしているモードで、ElasiCache Redis がリリースされた当時から存在するモードです。対するクラスターモードは、文字通り Redis Cluster をバックエンドにしているモードで、シャーディングなどがサポートされたちゃんとしたクラスターです。

クラスターモードについては以下の公式ドキュメントがわかりやすいです。

- [ElastiCache クラスター - Amazon ElastiCache](http://docs.aws.amazon.com/ja_jp/AmazonElastiCache/latest/UserGuide/Clusters.html)
- [レプリケーション: Redis (クラスターモードが無効) と Redis (クラスターモードが有効) - Amazon ElastiCache](http://docs.aws.amazon.com/ja_jp/AmazonElastiCache/latest/UserGuide/Replication.Redis-RedisCluster.html)

公式ドキュメントにあるように両者にはいろいろと違いがあるのですが、上述のページに書かれていない地味に便利そうなポイントとして、クラスターモードの場合は t2 インスタンスでも自動フェイルオーバを有効にできる、ということがあります。対する非クラスターモードでは、cache.m3.medium 以上のインスタンスタイプでないと自動フェイルオーバを有効にできないという制限があります。

「じゃあ m3 にすればええやん！」と思われるかもしれませんが、マイクロサービス化や ECS & Hako で新規アプリケーションの立ち上げが増えている今、新たな Redis が必要だが m3 だとオーバースペックだ、というようなシチュエーションが実際に発生しています。コスト面を考えると、t2 で済むならそれを使っていきたいのです。

クラスターモードだとややこしくなると思われるかもしれませんが、シャード数を 1 に設定しレプリカを 1 に設定すれば、クラスターモードが無効で primary 1 台、replica 1 台で構成した場合とほぼ同じような構成になります。

ただし、Rails から利用することを考えると現状クラスターモードは使いものにならず、t2 インスタンスで自動フェイルオーバを組むことはできません。なぜなら、Redis Cluster を使うためにはクライアントが Redis Cluster に対応している必要があるからです。

Ruby 界隈ではいわゆる [Redis gem](https://github.com/redis/redis-rb) がデファクトスタンダードです。2017-11-05 現在、この gem では Redis Cluster に対応しておらず、PR 上でレビューされているという状態のようです ([Add Redis Cluster support by supercaracal · Pull Request #716 · redis/redis-rb](https://github.com/redis/redis-rb/pull/716))。というわけで、Rails アプリケーションから Redis Cluster を使うことができるようになるのは、もう少し先の話となりそうです。


## Redis Sentinel で HA 構成

というわけで、ElastiCache Redis を使うことはあきらめて、Redis on EC2 (Ubuntu 16.04) に移行することにしました。

次に考えることは、どのようにして HA 構成にするかという点です。ElastiCache だと multi-az での自動フェイルオーバを簡単に使うことができるので何も考えなくてよいですが、EC2 に Redis をのせるならば自前で自動フェイルオーバを組む必要があります。

自動フェイルオーバできるようにするためにはいくつかのやり方が考えられます。今回は 2 台の Redis を active/standby 構成にすることを考えます。

- Pacemaker や Heartbeat を使って、相方が死んだら VIP を切り替えるのを自前でやる (古典的)
- Redis Sentinel を使う
- Redis Cluster を自前で組む

このうち、Redis Cluster は真っ先に候補から外れます。なぜなら、余談にも書いたように Redis gem が Redis Cluster をサポートしていないからです。

Pacemaker や Heartbeat を使うやり方では、slave を master に昇格したときにアプリが書き込みたいデータのロストを最小にする、split brain に陥らないようにどうにかする、などなどの工夫を自前で全てやる必要があります。最近 [本当は恐ろしい分散システムの話](https://www.slideshare.net/kumagi/ss-81368169) というスライドが話題になっていましたが、Redis 作者の「ユーザお手製のスクリプトで同じような事をするよりは依然として 99% マシな選択肢である」という言葉の通り、Redis Sentinel や Redis Cluster という選択肢がある今、あまり良手ではないでしょう。

というわけで、Redis Sentinel を実戦投入したいなと思って、ドキュメントを読みつつちょっと手を動かして検証してみました。以下は [Redis Sentinel Documentation – Redis](https://redis.io/topics/sentinel) を読んで理解したことの要約に、わたしの思うところをちょい足ししたような文章になっています。


### Redis Sentinel でできること

- モニタリング: master と slave が期待通りに動いているかを監視できる。
- 通知: API を通じて監視しているインスタンスに異常が起こったときに通知できる。
- 自動フェイルオーバ: master がダウンしたときに slave を master に昇格できる。
- Configuration provider: サービスディスカバリとして動作し、Sentinel に接続しているクライアントに master の情報 (IP アドレスとポート) を知らせることができる。

つまり、Sentinel を使えば自動フェイルオーバが可能などころか、クライアントが Sentinel に対応していれば VIP の付け替えなどの仕組みを用意せずとも、フェイルオーバ後の master に再接続させることができる、ということです。ただし、Redis では非同期レプリケーションとなるため、ある程度のデータロスト (書き込んだはずのデータが書き込まれない) は許容し、そうなっても問題ないようにアプリケーションを作る必要があります (軽減する方法はあります)。


### Redis Sentinel は分散システムである

Redis Sentinel は分散システムであり、それ自体がクラスタです。どのような故障クラスにも耐えうるわけではないですが、適切に構成できれば、Sentinel 自身に相応に十分な耐故障性をもたせられる上、誤検知による不必要なフェイルオーバが始まってしまう確率を減らすことができます。

Sentinel によるフェイルオーバは、ざっくり以下のような感じで動きます。

- quorum に設定した数以上の Sentinel が master がダウンしたと判断した場合に、Sentinel 全体として「その master はダウンした」と合意する。
- 多数決によるリーダー選出を行い、フェイルオーバをするために動く Sentinel をひとり選ぶ。
- ^ で選ばれた Sentinel が適切だと思われる slave をひとり選び、master に昇格するように設定を再構成する。
- Sentinel に接続しているクライアントは master が切り替わったことを検知し、書き込みを新 master に向ける。

quorum は好きな数を設定することができます。quorum を小さく設定することで素早くフェイルオーバを開始できる代わりに、誤検知の可能性も増えるでしょう。逆に quorum を大きく設定することにより、フェイルオーバが遅くなる代わりに誤検知の可能性を減らすことができます。

ここで注意すべきは、フェイルオーバを実行するために多数決によるリーダー選出が行われる、というところです。つまり、Sentinel 全体で過半数のノードが死んでしまっている場合、残念ながら自動フェイルオーバが実行されることはありません。

たとえば 5 コの Sentinel プロセスがあり、quorum が 2 に設定されていると、以下のように動作します。

- もし 2 コ以上の Sentinel がある master がダウンしたと判定したらフェイルオーバのプロセスを開始する。
- もし 3 コ以上の Sentinel が生きていれば、多数決合意により選出されたリーダーがフェイルオーバの処理を行う。

### Sentinel クラスタの構成例

#### Example 1: just two Sentinels, DON'T DO THIS

ドキュメントにはいくつかの構成例が載っています。たとえば、Example 1 はこんな感じです。

```
+----+         +----+
| M1 |---------| R1 |
| S1 |         | S2 |
+----+         +----+

Configuration: quorum = 1
```

四角はボックス、つまり 1 台のインスタンスを示しており、その中で Redis インスタンスが動いています。M1 は master、R1 は slave (R は replica の R) で、S1 および S2 は Sentinel プロセスたちです。

分散システムをかじったことのある人なら、この図をみただけで「あっ・・・」という感じでニンマリできることでしょう。この構成では左のインスタンスと右のインスタンスの接続が切れると split brain に陥り、悲しいことになってしまいます。

```
+----+           +------+
| M1 |----//-----| [M1] |
| S1 |           | S2   |
+----+           +------+
```

S2 は M1 がダウンしたと検知して右のインスタンスの Redis を master に昇格しますが、左のインスタンスも依然自分を master だと思っているので、一つのレプリケーショングループの中で master がふたりになってしまいました。試合終了です。

#### Example 2: basic setup with three boxes

```
       +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+

Configuration: quorum = 2
```

Example 1 で見たように、典型的な split brain を避けるために Sentinel クラスタには最低でも 3 コ以上のインスタンスが必要です。これは分散システムに一般的なことで、Elsticsearch なども 3 台以上で構成することが普通です。Example 2 は quorum = 2 かつ過半数が 2 なので、1 台のクラッシュまでなら Sentinel は正しく動作することができます。

ただし、以下のような状態に陥ることがあるので注意が必要なパターンです。

```
         +----+
         | M1 |
         | S1 | <- C1 (writes will be lost)
         +----+
            |
            /
            /
+------+    |    +----+
| [M2] |----+----| R3 |
| S2   |         | S3 |
+------+         +----+
```

もし M1 からのびている接続が切れてネットワークが分断されてしまった状態になると、S2 と S3 で合意してどちらかのインスタンスが master に昇格します。この図では R2 が昇格しました。ただし、もし M1 に書き込んでいるクライアント C1 が M1 と同じ分断されたネットワークに存在して M2 と R3 から分断されてしまった場合、C1 は M1 に対してネットワークが回復するまで健気に書き込み続けることになり、その間のデータはロストします。ネットワークが回復すると M1 は slave に降格しますが、分断が起こってからこの間に書き込まれたデータは全て失われます。

このようなデータロストを少しでも軽減するために、このような構成をとる場合は、master に以下のような設定を書いておくことが推奨されます。

```
min-slaves-to-write 1
min-slaves-max-lag 10
```

これは「2 台の slave と接続が 10 秒以上切断されていた場合に書き込みを禁止する」というような設定です。`min-slaves-to-write 1` は master に書き込むためには最低 1 台の slave が存在していなければならない、という意味です。このようにしておくことで、上述のパターンでは最大 10 秒間の書き込みはロストしますが、それ以降のロストは防ぐことができます。ただし、この場合 slave が 2 台ともダウンすると Sentinel は機能しなくなりますし、M1 へ書き込むこともできなくなるため、レプリケーショングループ全体として完全にダウンした状態になることは避けられません。これはトレードオフです。

#### その他の Example

Example 3 ではクライアント側に Sentinel を持たせる例で、Example 4 は master/slave を 1 台ずつにして Sentinel を同居させたいが、それでは典型的な split brain に陥るためクライアントにも Sentinel を持たせる、というようなパターンです。


#### 結局どういう構成にすればいいの？

これらの Example にあるように、Sentinel の構成パターンは様々で、それぞれにメリットデメリットがあります。そして、Example では紹介されていませんが、ひとつの Sentinel クラスタで複数の master を監視することもできるため、Sentinel だけが動くインスタンスを複数用意してクラスタリングし、複数のレプリケーショングループを監視させるという構成も考えられます。

わたしは Sentinel が Redis やクライアントと同居しているよりも、Sentinel だけが動く小さい t2 インスタンスを複数の AZ にまたがって 3 コ以上並べてクラスタリングするがいいかなと思っており、実戦投入するならばそのような構成にしようと思っています。レプリケーショングループごとに Sentinel クラスタが存在するのは煩雑ですし、そもそも active/standby 構成にすると 2 台になるので、split brain になる危険性があります。かといってクライアントに Sentinel を持たせるにしても、app および app-pantry はオートスケーリングによって増減するため、quorum をどうやって設定するねん、というような問題も出る上、Rails と同居するミドルウェアが増えるのも少しいやです。

